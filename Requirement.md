# YOLO物体検出アプリケーション 要件定義

このプロジェクトは、YOLO（You Only Look Once）物体検出モデルのためのアノテーションと推論を行うWebアプリケーションです。

## プロジェクトの目的

YOLOモデルのアノテーションから推論までを一貫して管理できるWebアプリケーションを構築すること。

## 技術スタック

- **フレームワーク**: Django（Python Webフレームワーク）
- **機械学習**: YOLOv9モデル（物体検出用の深層学習モデル）
- **学習環境**: Google Colab（クラウドベースのJupyterノートブック環境）
- **認証**: ログイン機能は不要（認証なしでアクセス可能）

## 主な機能とワークフロー
1. データインポート機能
   - YOLO学習用の画像データセットをアプリケーションにインポート

2. アノテーション機能
   - インポートした画像に対して、物体の位置情報（バウンディングボックス）とクラスラベルを付与
   - アノテーションとは、画像内の物体に「どこに何があるか」を手動でマーキングする作業

3. データエクスポート機能
   - アノテーション済みデータセットをYOLO学習用フォーマット（YOLO形式のテキストファイルと画像のセット）でエクスポート

4. モデル学習機能
   - エクスポートしたデータセットをGoogle Colab上で使用してYOLOモデルを学習
   - 学習が完了すると、物体検出が可能な学習済みモデルファイル（.pt形式など）が生成される

5. モデルインポート機能
   - Colabで学習したモデルファイルをアプリケーションにインポート

6. 推論機能
   - インポートした学習済みモデルを使用して、新しい画像に対して物体検出の推論（予測）を実行
   - 推論結果として、検出された物体の位置とクラスが表示される

## 機能要件

### 画面0: ホーム画面

#### 0.1 画面概要
- **目的**: アプリケーションのメインエントリーポイント（最初に表示される画面）
- **配置**: アプリケーション起動時に最初に表示される画面

#### 0.2 ナビゲーションボタン
- **配置**: 画面中央または適切な位置に配置
- **ボタン構成**:
  - **「Train用アノテーション」ボタン**: 画面1（train用のアノテーション作成画面）に遷移
  - **「Val用アノテーション」ボタン**: 画面2（val用のアノテーション作成画面）に遷移
  - **「推論実行」ボタン**: 画面3（推論実行画面）に遷移
- **デザイン**:
  - 各ボタンは視覚的に区別しやすいデザイン（アイコンや説明文の追加も可）
  - レスポンシブ対応（画面サイズに応じて適切なレイアウトに変更）
  - タッチ操作に適したボタンサイズを確保（小画面時）

#### 0.3 画面遷移
- **動作**: 各ボタンをクリックすると、対応する画面に遷移する

### 画面1: train用のアノテーション作成画面

#### 1.1 画像インポート機能
- **方法**: ドラッグ&ドロップまたはファイル選択ダイアログ
- **対応形式**: 一般的な画像形式（jpg, png, jpeg等）
- **動作**: インポートした画像は即座に画面に表示される
- **複数選択**: 複数画像の一括インポートに対応

#### 1.2 画像表示エリア
- **配置**: メインエリア
- **機能**: 
  - インポートした画像を一覧表示（アノテーション作業がしやすい適切なサイズで表示）
  - 画像上でマウス操作による矩形描画が可能
  - **一覧表示でのアノテーション**: インポートした画像を一覧表示した状態のまま、各画像に対して直接アノテーションを実行できる（別画面への遷移や個別表示への切り替えは不要）

#### 1.3 クラス管理パネル（左側）
- **配置**: 
  - **大画面（デスクトップなど）**: 画面左側に固定サイドバーとして配置
  - **小画面（タブレット・スマートフォンなど）**: レスポンシブ対応により、画面サイズに応じた適切なデザインに変更
    - 例: ハンバーガーメニューやドロワーメニューとして表示、または画面下部にタブ形式で表示など
- **機能**:
  - クラス一覧の表示
  - 「追加」ボタンで新しいクラスを追加（クラス名・色を入力）
  - クラスをクリックして選択状態にする（選択中のクラスは視覚的に区別）
  - 選択したクラスがアノテーションに適用される
- **レスポンシブ対応**:
  - 小さい画面でも操作性が落ちないよう、タッチ操作に適したUI要素のサイズを確保
  - クラス管理パネルの表示/非表示を切り替えられる機能を提供（小画面時）

#### 1.4 アノテーション機能
- **操作フロー**:
  1. 左側パネルでクラスを選択
  2. 画像上でマウスドラッグして矩形（バウンディングボックス）を描画
  3. 矩形が描画されると、選択中のクラスが自動的に割り当てられる
- **表示**: 矩形は色分けして表示（クラスごとに異なる色）
- **編集**: 既存の矩形を選択して削除または修正可能

#### 1.5 エクスポート機能
- **ボタン**: 「完了」ボタンを画面に配置
- **確認画面**: モーダルで「エクスポートしてもいいですか？」と確認し、「エクスポート」ボタンで出力開始
- **ダウンロード方法**: ブラウザのダウンロード機能を使用してダウンロード
- **保存先**: ブラウザのデフォルトダウンロードフォルダ（通常はユーザーのダウンロードフォルダ）
- **出力形式**: `train.zip` ファイルとしてダウンロード（展開すると以下の構造）
  ```
  train/
  ├── images/
  │   ├── image001.jpg
  │   ├── image002.jpg
  │   └── ...
  ├── labels/
  │   ├── image001.txt
  │   ├── image002.txt
  │   └── ...
  └── dataset.yaml
  ```
- **出力内容**:
  - **imagesフォルダ**: アノテーション対象の画像ファイル
  - **labelsフォルダ**: YOLO形式のテキストファイル（各画像に対応する.txtファイル）
    - **ファイル名**: `画像名.txt`（例: `image001.jpg` → `image001.txt`）
    - **フォーマット**: 正規化座標で以下の形式
      ```
      class_id center_x center_y width height
      ```
  - **dataset.yaml**: YOLO学習用のデータセット設定ファイル
    - **ファイル名**: `dataset.yaml`（train.zipのルートディレクトリに含まれる）
    - **内容**: trainのアノテーションで設定したクラス設定を反映したYAML形式の設定ファイル
    - **主要な設定項目**:
      - `path`: データセットのパス（`dataset`）
      - `train`: 訓練データのパス（`train`）
      - `validation`: 検証データのパス（`val`）
      - `class_num`: クラス数（設定したクラスの総数）
      - `class_list`: クラス名のリスト（設定したクラス名を順番に配列で記載）
      - `img_size`: 画像サイズ（1280,1280でいい）
      - `num_workers`: CPUワーカー数（2でいい）
    - **クラス設定の反映**:
      - 画面1で設定したクラス（クラス名）が`class_list`に反映される
      - クラスの順序は、設定した順序またはクラスIDの順序に従う
      - `class_num`は設定したクラスの総数が自動的に設定される

#### 1.6 次のステップへの遷移機能
- **ボタン**: 「次のステップへ」ボタンを画面に配置（エクスポート機能の「完了」ボタンと並べて配置、または別の適切な位置に配置）
- **動作**: ボタンをクリックすると、画面2（val用のアノテーション作成画面）に遷移
- **クラス設定の保持**: 
  - 画面1で設定したクラス（クラス名・色）の情報を保持したまま画面2に遷移
  - 画面2のクラス管理パネルには、画面1で設定したクラスが自動的に表示される
  - 画面2でもクラスの追加・編集・削除が可能（画面1で設定したクラスをベースに作業を継続できる）

### 画面2: val用のアノテーション作成画面

画面1と同様の機能を提供しますが、エクスポート先が異なります。

#### 2.1 画像インポート機能
画面1の1.1と同様

#### 2.2 画像表示エリア
画面1の1.2と同様（一覧表示でのアノテーション機能を含む）

#### 2.3 クラス管理パネル
画面1の1.3と同様（レスポンシブ対応を含む）
- **クラス設定の継承**:
  - 画面1から「次のステップへ」ボタンで遷移した場合、画面1で設定したクラス（クラス名・色）が自動的に読み込まれる
  - 画面2でもクラスの追加・編集・削除が可能（画面1で設定したクラスをベースに作業を継続できる）
  - ホーム画面から直接「Val用アノテーション」ボタンで遷移した場合は、空のクラス管理パネルから開始

#### 2.4 アノテーション機能
画面1の1.4と同様

#### 2.5 エクスポート機能（画面2）

- **ボタン**: 「完了」ボタンを画面に配置
- **確認画面**: モーダルで「エクスポートしてもいいですか？」と確認し、「エクスポート」ボタンで出力開始
- **ダウンロード方法**: ブラウザのダウンロード機能を使用してダウンロード
- **保存先**: ブラウザのデフォルトダウンロードフォルダ（通常はユーザーのダウンロードフォルダ）
- **出力形式**: `val.zip` ファイルとしてダウンロード（展開すると以下の構造）
  ```
  val/
  ├── images/
  │   ├── image001.jpg
  │   ├── image002.jpg
  │   └── ...
  └── labels/
      ├── image001.txt
      ├── image002.txt
      └── ...
  ```
- **出力内容**:
  - **imagesフォルダ**: アノテーション対象の画像ファイル
  - **labelsフォルダ**: YOLO形式のテキストファイル（各画像に対応する.txtファイル）
    - **ファイル名**: `画像名.txt`（例: `image001.jpg` → `image001.txt`）
    - **フォーマット**: 正規化座標で以下の形式
      ```
      class_id center_x center_y width height
      ```

#### 2.6 次のステップへの遷移機能（画面2）

- **ボタン配置**: エクスポート機能の「完了」ボタンと並べて配置、または別の適切な位置に配置
- **ボタン構成**:
  - **「Colabで学習する」ボタン**: Google Colabの学習用ノートブック（URL: `https://colab.research.google.com/drive/1gs3ujkr-Mw9_IVzg0NQ-n2VrtWdyAJQN?authuser=1`）を別タブで開く
    - **動作**: ボタンをクリックすると、新しいブラウザタブでColabのURLが開く
    - **用途**: エクスポートしたデータセットを使用してYOLOモデルを学習するためのColab環境にアクセス
  - **「推論画面へ移動」ボタン**: 画面3（推論実行画面）に遷移
    - **動作**: ボタンをクリックすると、画面3（推論実行画面）に遷移
    - **クラス設定の引き継ぎ**: 
      - 画面2で設定したクラス（クラス名・色）の情報を保持したまま画面3に遷移
      - 画面3では、引き継いだクラス設定を使用して推論結果を表示（検出された物体のクラス名と色を反映）

### 画面3: 推論実行画面

#### 3.0 クラス設定の引き継ぎ機能
- **クラス設定の読み込み**:
  - 画面2から「推論画面へ移動」ボタンで遷移した場合、画面2で設定したクラス（クラス名・色）が自動的に読み込まれる
  - ホーム画面から直接「推論実行」ボタンで遷移した場合は、空のクラス設定から開始
- **クラス設定の表示**:
  - 引き継いだクラス設定は、推論結果の表示時に使用される
  - 検出された物体のクラス名と色が、アノテーション画面で設定したものと一致するように表示される

#### 3.1 モデルインポート機能
- **対象**: Google Colabで学習した学習済み重みファイル（.pt形式）
- **方法**: ファイル選択ダイアログまたはドラッグ&ドロップ

#### 3.2 推論画像インポート機能
- **方法**: ドラッグ&ドロップまたはファイル選択ダイアログ
- **対応**: 単一画像または複数画像
- **表示**: インポートした画像をプレビュー表示

#### 3.3 推論設定機能
- **配置**: 推論実行前に設定可能なパネルまたはフォーム
- **設定項目**:
  - **img_size**: 推論時の入力画像サイズ（ピクセル単位、例: 640）
    - 画像を推論モデルに入力する際のリサイズサイズを指定
    - デフォルト値: 640
  - **num_workers (cpu_num)**: CPUワーカー数（並列処理の数）
    - 推論処理を並列実行する際のCPUスレッド数を指定
    - デフォルト値: 4（または利用可能なCPUコア数）
  - **min_confidence**: 最小信頼度（検出結果の信頼度の閾値）
    - 検出結果の信頼度がこの値以上のもののみを表示
    - 範囲: 0.0-1.0
    - デフォルト値: 0.25
  - **min_iou**: 最小IoU（Non-Maximum SuppressionのIoU閾値）
    - 重複する検出結果を統合する際のIoU（Intersection over Union）閾値
    - 範囲: 0.0-1.0
    - デフォルト値: 0.45
  - **max_bbox**: 最大バウンディングボックス数（1画像あたりの最大検出数）
    - 1枚の画像に対して最大何個の物体を検出するかを指定
    - デフォルト値: 300
- **UI**: 各設定項目は数値入力フィールドで設定可能（スライダーやドロップダウンも可）

#### 3.4 推論実行機能
- **ボタン**: 「推論開始」ボタン
- **処理**:
  1. インポート済みの学習済みモデルを読み込む
  2. 推論設定（img_size、num_workers、min_confidence、min_iou、max_bbox）を適用
  3. 推論画像に対して物体検出を実行
  4. 検出結果を画像上に描画（バウンディングボックス + クラス名 + 信頼度スコア）

#### 3.5 結果表示機能
- **表示内容**:
  - 検出された物体のバウンディングボックス
  - クラス名
  - 信頼度スコア（0.0-1.0）
- **保存**: 推論結果画像を保存できる機能

## データフロー

### アノテーション → 学習用データセット

```
画像インポート → アノテーション作成 → エクスポート
```

### 推論フロー

```
学習済みモデル(.pt)インポート → 推論画像インポート → 推論設定 → 推論実行 → 結果表示
```

## 実装の優先順位

1. **Phase 1**: 基本的なDjangoプロジェクトセットアップ + Docker環境構築 + ホーム画面（画面0）の実装
2. **Phase 2**: 画面1（train用のアノテーション作成画面）と画面2（val用のアノテーション作成画面）の実装
3. **Phase 3**: 画面3（推論実行画面）の実装
4. **Phase 4**: yolov9フォルダーの整理と統合